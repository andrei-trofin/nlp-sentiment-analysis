{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf75bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from pickle import dump\n",
    "from scipy.sparse import save_npz\n",
    "import spacy\n",
    "from spacy import vectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dabb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww bummer shoulda got david carr day wink_smirk</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset updat facebook text cri result school to...</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive time ball manag save 50 rest bound</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bodi feel itchi like fire</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav mad</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  word_count  \\\n",
       "0          0  awww bummer shoulda got david carr day wink_smirk          19   \n",
       "1          0  upset updat facebook text cri result school to...          21   \n",
       "2          0            dive time ball manag save 50 rest bound          18   \n",
       "3          0                          bodi feel itchi like fire          10   \n",
       "4          0                                          behav mad          21   \n",
       "\n",
       "   character_count  avg_word_len  stop_words_count  hashtags_count  \\\n",
       "0              115      5.052632                 6               0   \n",
       "1              111      4.285714                 9               0   \n",
       "2               89      3.944444                 9               0   \n",
       "3               47      3.700000                 5               0   \n",
       "4              111      4.285714                11               0   \n",
       "\n",
       "   numeric_count  upper_case_count  email_count  url_count  mention_count  \\\n",
       "0              0                 0            0          1              0   \n",
       "1              0                 0            0          0              0   \n",
       "2              0                 0            0          0              0   \n",
       "3              0                 0            0          0              0   \n",
       "4              0                 0            0          0              0   \n",
       "\n",
       "   is_reply  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(\"../data/preprocessed_step_1.csv\", index_col=0)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfdb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the message into string type to avoid cast problems\n",
    "twitter_df['message'] = twitter_df[\"message\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629a805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the preprocessing, some messages contain now null values. We will replace these values with empty strings.\n",
    "twitter_df[\"message\"] = twitter_df[\"message\"].fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ada972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, message, word_count, character_count, avg_word_len, stop_words_count, hashtags_count, numeric_count, upper_case_count, email_count, url_count, mention_count, is_reply]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that no other message is null\n",
    "twitter_df.loc[twitter_df[\"message\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca81ebe",
   "metadata": {},
   "source": [
    "### Data split\n",
    "\n",
    "Because the following preprocessing will be mostly based on the rows of the data we have, to ensure proper independence, we will already split the data set into training and test.\n",
    "\n",
    "In this way, we will move one step away from overfitting whatever model we will train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d292e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    twitter_df.drop(columns=\"sentiment\"), twitter_df[\"sentiment\"],\n",
    "    stratify=twitter_df[\"sentiment\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d318f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data because we will use it later to test our models.\n",
    "# Train data does not need to be stored because we will process it further down the line.\n",
    "# Test data will go through the same processing, but not in this notebook.\n",
    "X_test.to_csv(\"../data/X_test.csv\")\n",
    "y_test.to_csv(\"../data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eff19b",
   "metadata": {},
   "source": [
    "### Most frequent words\n",
    "\n",
    "In NLP, if a word is too frequent, it loses its meaning. It's \"like\" using \"like\". We want to avoid using them as features for our training models. However, some words might be occuring very often, but convey a specific meaning, like the word \"great\".\n",
    "Therefore, we want to find the most occuring words, see the proportions of the sentiments in which they occur and remove those frequent words that appear both in negative and positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa34595",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_words =  pd.Series(\" \".join(X_train[\"message\"]).split()).value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6d54c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day         83252\n",
       "good        73812\n",
       "work        70015\n",
       "like        66738\n",
       "love        66021\n",
       "quot        58559\n",
       "today       54698\n",
       "time        52871\n",
       "go          51360\n",
       "got         49158\n",
       "thank       47465\n",
       "lol         47426\n",
       "want        45793\n",
       "miss        45516\n",
       "know        43934\n",
       "feel        41019\n",
       "think       40875\n",
       "im          40570\n",
       "don         39954\n",
       "amp         39139\n",
       "night       36231\n",
       "hope        35866\n",
       "watch       34881\n",
       "need        34742\n",
       "new         33804\n",
       "home        32374\n",
       "ll          32258\n",
       "look        31643\n",
       "oh          31546\n",
       "come        31148\n",
       "twitter     28605\n",
       "morn        28530\n",
       "tomorrow    27359\n",
       "wish        27154\n",
       "great       26972\n",
       "wait        26055\n",
       "sleep       25848\n",
       "haha        25294\n",
       "sad         23954\n",
       "fun         22960\n",
       "get         22909\n",
       "right       22503\n",
       "week        22497\n",
       "tri         22457\n",
       "follow      22217\n",
       "happi       22163\n",
       "bad         21909\n",
       "ve          21302\n",
       "sorri       21133\n",
       "thing       21130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ae28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of boolean values which for columns it has the 50 most frequent words + 1 column for sentiment\n",
    "# and for indexes, the indexes of the twitter entries. The value in 1 cell will be true if the word in the column \n",
    "# is in the tweet\n",
    "top50_words_df = pd.DataFrame(index=X_train.index, columns=top50_words.index.values)\n",
    "for col in top50_words_df.columns:\n",
    "    top50_words_df.loc[:, col] = X_train[\"message\"].apply(lambda x: True if col in x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41370f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>good</th>\n",
       "      <th>work</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>quot</th>\n",
       "      <th>today</th>\n",
       "      <th>time</th>\n",
       "      <th>go</th>\n",
       "      <th>got</th>\n",
       "      <th>...</th>\n",
       "      <th>right</th>\n",
       "      <th>week</th>\n",
       "      <th>tri</th>\n",
       "      <th>follow</th>\n",
       "      <th>happi</th>\n",
       "      <th>bad</th>\n",
       "      <th>ve</th>\n",
       "      <th>sorri</th>\n",
       "      <th>thing</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657423</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608008</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007477</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042354</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           day   good   work   like   love   quot  today   time     go    got  \\\n",
       "657423    True  False  False   True  False  False  False  False   True   True   \n",
       "608008   False  False  False  False  False  False  False  False  False  False   \n",
       "12545     True  False  False  False  False  False  False  False  False  False   \n",
       "1007477   True  False   True  False  False  False  False  False  False  False   \n",
       "1042354  False  False  False  False  False  False  False  False   True   True   \n",
       "\n",
       "         ...  right   week    tri  follow  happi    bad     ve  sorri  thing  \\\n",
       "657423   ...   True  False  False   False  False  False  False  False  False   \n",
       "608008   ...  False  False  False   False  False  False  False  False  False   \n",
       "12545    ...  False  False  False   False  False  False  False  False  False   \n",
       "1007477  ...  False  False  False   False  False  False   True  False  False   \n",
       "1042354  ...  False  False  False   False  False  False  False  False  False   \n",
       "\n",
       "         sentiment  \n",
       "657423           0  \n",
       "608008           0  \n",
       "12545            0  \n",
       "1007477          4  \n",
       "1042354          4  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_words_df = pd.concat([top50_words_df, y_train], axis=1)\n",
    "top50_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e263718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word, count if it appeared in a positive or negative message\n",
    "top50_words_split_df = pd.DataFrame(columns = top50_words_df.columns.values)\n",
    "top50_words_split_df.loc[0, :] = top50_words_df.loc[top50_words_df[\"sentiment\"] == 0].sum(axis=0)\n",
    "top50_words_split_df.loc[4, :] = top50_words_df.loc[top50_words_df[\"sentiment\"] == 4].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454cd812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>87797</td>\n",
       "      <td>89612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>25916</td>\n",
       "      <td>52983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>50050</td>\n",
       "      <td>25195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>33248</td>\n",
       "      <td>31142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>17334</td>\n",
       "      <td>47317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quot</th>\n",
       "      <td>10274</td>\n",
       "      <td>17909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>30198</td>\n",
       "      <td>23936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>24889</td>\n",
       "      <td>27127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>113276</td>\n",
       "      <td>125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>34342</td>\n",
       "      <td>26911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>6755</td>\n",
       "      <td>41090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>18157</td>\n",
       "      <td>28583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>31359</td>\n",
       "      <td>13319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss</th>\n",
       "      <td>38721</td>\n",
       "      <td>8388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>22259</td>\n",
       "      <td>21694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>29380</td>\n",
       "      <td>11635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>21519</td>\n",
       "      <td>19406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>63237</td>\n",
       "      <td>60157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>39166</td>\n",
       "      <td>21160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>19597</td>\n",
       "      <td>22339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>29075</td>\n",
       "      <td>32883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hope</th>\n",
       "      <td>16278</td>\n",
       "      <td>19363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>14762</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>21042</td>\n",
       "      <td>13413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>16559</td>\n",
       "      <td>24907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>22176</td>\n",
       "      <td>13972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>79788</td>\n",
       "      <td>92958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>14518</td>\n",
       "      <td>17706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>23168</td>\n",
       "      <td>21224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>15837</td>\n",
       "      <td>15567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>12356</td>\n",
       "      <td>18772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morn</th>\n",
       "      <td>11905</td>\n",
       "      <td>17967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomorrow</th>\n",
       "      <td>15346</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>21320</td>\n",
       "      <td>6056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>7167</td>\n",
       "      <td>20605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>11351</td>\n",
       "      <td>15168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>20073</td>\n",
       "      <td>10859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haha</th>\n",
       "      <td>11116</td>\n",
       "      <td>25233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>25919</td>\n",
       "      <td>2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>11252</td>\n",
       "      <td>20063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>16099</td>\n",
       "      <td>14086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>13504</td>\n",
       "      <td>12725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>19941</td>\n",
       "      <td>16908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tri</th>\n",
       "      <td>19642</td>\n",
       "      <td>16707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>6124</td>\n",
       "      <td>17046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happi</th>\n",
       "      <td>5748</td>\n",
       "      <td>16697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>18400</td>\n",
       "      <td>5041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>81971</td>\n",
       "      <td>103458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorri</th>\n",
       "      <td>16554</td>\n",
       "      <td>4266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>11118</td>\n",
       "      <td>10469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       4\n",
       "day        87797   89612\n",
       "good       25916   52983\n",
       "work       50050   25195\n",
       "like       33248   31142\n",
       "love       17334   47317\n",
       "quot       10274   17909\n",
       "today      30198   23936\n",
       "time       24889   27127\n",
       "go        113276  125205\n",
       "got        34342   26911\n",
       "thank       6755   41090\n",
       "lol        18157   28583\n",
       "want       31359   13319\n",
       "miss       38721    8388\n",
       "know       22259   21694\n",
       "feel       29380   11635\n",
       "think      21519   19406\n",
       "im         63237   60157\n",
       "don        39166   21160\n",
       "amp        19597   22339\n",
       "night      29075   32883\n",
       "hope       16278   19363\n",
       "watch      14762   20904\n",
       "need       21042   13413\n",
       "new        16559   24907\n",
       "home       22176   13972\n",
       "ll         79788   92958\n",
       "look       14518   17706\n",
       "oh         23168   21224\n",
       "come       15837   15567\n",
       "twitter    12356   18772\n",
       "morn       11905   17967\n",
       "tomorrow   15346   11800\n",
       "wish       21320    6056\n",
       "great       7167   20605\n",
       "wait       11351   15168\n",
       "sleep      20073   10859\n",
       "haha       11116   25233\n",
       "sad        25919    2128\n",
       "fun        11252   20063\n",
       "get        16099   14086\n",
       "right      13504   12725\n",
       "week       19941   16908\n",
       "tri        19642   16707\n",
       "follow      6124   17046\n",
       "happi       5748   16697\n",
       "bad        18400    5041\n",
       "ve         81971  103458\n",
       "sorri      16554    4266\n",
       "thing      11118   10469"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_words_split_df = top50_words_split_df.drop(columns=\"sentiment\").T\n",
    "top50_words_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2242dc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>negative_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>87797</td>\n",
       "      <td>89612</td>\n",
       "      <td>0.494885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>25916</td>\n",
       "      <td>52983</td>\n",
       "      <td>0.328471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>50050</td>\n",
       "      <td>25195</td>\n",
       "      <td>0.66516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>33248</td>\n",
       "      <td>31142</td>\n",
       "      <td>0.516353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>17334</td>\n",
       "      <td>47317</td>\n",
       "      <td>0.268117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quot</th>\n",
       "      <td>10274</td>\n",
       "      <td>17909</td>\n",
       "      <td>0.364546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>30198</td>\n",
       "      <td>23936</td>\n",
       "      <td>0.557838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>24889</td>\n",
       "      <td>27127</td>\n",
       "      <td>0.478487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>113276</td>\n",
       "      <td>125205</td>\n",
       "      <td>0.47499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>34342</td>\n",
       "      <td>26911</td>\n",
       "      <td>0.560658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>6755</td>\n",
       "      <td>41090</td>\n",
       "      <td>0.141185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>18157</td>\n",
       "      <td>28583</td>\n",
       "      <td>0.388468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>31359</td>\n",
       "      <td>13319</td>\n",
       "      <td>0.701889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss</th>\n",
       "      <td>38721</td>\n",
       "      <td>8388</td>\n",
       "      <td>0.821945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>22259</td>\n",
       "      <td>21694</td>\n",
       "      <td>0.506427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>29380</td>\n",
       "      <td>11635</td>\n",
       "      <td>0.716323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>21519</td>\n",
       "      <td>19406</td>\n",
       "      <td>0.525816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>63237</td>\n",
       "      <td>60157</td>\n",
       "      <td>0.51248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>39166</td>\n",
       "      <td>21160</td>\n",
       "      <td>0.649239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>19597</td>\n",
       "      <td>22339</td>\n",
       "      <td>0.467307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>29075</td>\n",
       "      <td>32883</td>\n",
       "      <td>0.46927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hope</th>\n",
       "      <td>16278</td>\n",
       "      <td>19363</td>\n",
       "      <td>0.456721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>14762</td>\n",
       "      <td>20904</td>\n",
       "      <td>0.413896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>21042</td>\n",
       "      <td>13413</td>\n",
       "      <td>0.61071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>16559</td>\n",
       "      <td>24907</td>\n",
       "      <td>0.399339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>22176</td>\n",
       "      <td>13972</td>\n",
       "      <td>0.613478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>79788</td>\n",
       "      <td>92958</td>\n",
       "      <td>0.46188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>14518</td>\n",
       "      <td>17706</td>\n",
       "      <td>0.450534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>23168</td>\n",
       "      <td>21224</td>\n",
       "      <td>0.521896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>15837</td>\n",
       "      <td>15567</td>\n",
       "      <td>0.504299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>12356</td>\n",
       "      <td>18772</td>\n",
       "      <td>0.396942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morn</th>\n",
       "      <td>11905</td>\n",
       "      <td>17967</td>\n",
       "      <td>0.398534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomorrow</th>\n",
       "      <td>15346</td>\n",
       "      <td>11800</td>\n",
       "      <td>0.565313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>21320</td>\n",
       "      <td>6056</td>\n",
       "      <td>0.778784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>7167</td>\n",
       "      <td>20605</td>\n",
       "      <td>0.258066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>11351</td>\n",
       "      <td>15168</td>\n",
       "      <td>0.428033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>20073</td>\n",
       "      <td>10859</td>\n",
       "      <td>0.64894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haha</th>\n",
       "      <td>11116</td>\n",
       "      <td>25233</td>\n",
       "      <td>0.305813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>25919</td>\n",
       "      <td>2128</td>\n",
       "      <td>0.924127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>11252</td>\n",
       "      <td>20063</td>\n",
       "      <td>0.359317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>16099</td>\n",
       "      <td>14086</td>\n",
       "      <td>0.533344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>13504</td>\n",
       "      <td>12725</td>\n",
       "      <td>0.51485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>19941</td>\n",
       "      <td>16908</td>\n",
       "      <td>0.541154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tri</th>\n",
       "      <td>19642</td>\n",
       "      <td>16707</td>\n",
       "      <td>0.540372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>6124</td>\n",
       "      <td>17046</td>\n",
       "      <td>0.264307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happi</th>\n",
       "      <td>5748</td>\n",
       "      <td>16697</td>\n",
       "      <td>0.256093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>18400</td>\n",
       "      <td>5041</td>\n",
       "      <td>0.784949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>81971</td>\n",
       "      <td>103458</td>\n",
       "      <td>0.442061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorri</th>\n",
       "      <td>16554</td>\n",
       "      <td>4266</td>\n",
       "      <td>0.795101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>11118</td>\n",
       "      <td>10469</td>\n",
       "      <td>0.515032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       4 negative_ratio\n",
       "day        87797   89612       0.494885\n",
       "good       25916   52983       0.328471\n",
       "work       50050   25195        0.66516\n",
       "like       33248   31142       0.516353\n",
       "love       17334   47317       0.268117\n",
       "quot       10274   17909       0.364546\n",
       "today      30198   23936       0.557838\n",
       "time       24889   27127       0.478487\n",
       "go        113276  125205        0.47499\n",
       "got        34342   26911       0.560658\n",
       "thank       6755   41090       0.141185\n",
       "lol        18157   28583       0.388468\n",
       "want       31359   13319       0.701889\n",
       "miss       38721    8388       0.821945\n",
       "know       22259   21694       0.506427\n",
       "feel       29380   11635       0.716323\n",
       "think      21519   19406       0.525816\n",
       "im         63237   60157        0.51248\n",
       "don        39166   21160       0.649239\n",
       "amp        19597   22339       0.467307\n",
       "night      29075   32883        0.46927\n",
       "hope       16278   19363       0.456721\n",
       "watch      14762   20904       0.413896\n",
       "need       21042   13413        0.61071\n",
       "new        16559   24907       0.399339\n",
       "home       22176   13972       0.613478\n",
       "ll         79788   92958        0.46188\n",
       "look       14518   17706       0.450534\n",
       "oh         23168   21224       0.521896\n",
       "come       15837   15567       0.504299\n",
       "twitter    12356   18772       0.396942\n",
       "morn       11905   17967       0.398534\n",
       "tomorrow   15346   11800       0.565313\n",
       "wish       21320    6056       0.778784\n",
       "great       7167   20605       0.258066\n",
       "wait       11351   15168       0.428033\n",
       "sleep      20073   10859        0.64894\n",
       "haha       11116   25233       0.305813\n",
       "sad        25919    2128       0.924127\n",
       "fun        11252   20063       0.359317\n",
       "get        16099   14086       0.533344\n",
       "right      13504   12725        0.51485\n",
       "week       19941   16908       0.541154\n",
       "tri        19642   16707       0.540372\n",
       "follow      6124   17046       0.264307\n",
       "happi       5748   16697       0.256093\n",
       "bad        18400    5041       0.784949\n",
       "ve         81971  103458       0.442061\n",
       "sorri      16554    4266       0.795101\n",
       "thing      11118   10469       0.515032"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_words_split_df[\"negative_ratio\"] = top50_words_split_df[0] / (top50_words_split_df[0] + top50_words_split_df[4])\n",
    "top50_words_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56821d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['day', 'like', 'quot', 'today', 'time', 'go', 'got', 'lol', 'know',\n",
       "       'think', 'im', 'don', 'amp', 'night', 'hope', 'watch', 'need',\n",
       "       'new', 'home', 'll', 'look', 'oh', 'come', 'twitter', 'morn',\n",
       "       'tomorrow', 'wait', 'sleep', 'fun', 'get', 'right', 'week', 'tri',\n",
       "       've', 'thing'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll consider a word impactful if the difference between negative and positive tweets it appears in is more than 30%.\n",
    "# That means that a tweet is 2 times more likely to be a certain way if it has this word in it. Therefore, we will remove\n",
    "# the most common words with a negative ratio between 33% and 66%.\n",
    "\n",
    "to_remove_list = top50_words_split_df.loc[(top50_words_split_df[\"negative_ratio\"] > 0.33)\n",
    "                                           & (top50_words_split_df[\"negative_ratio\"] < 0.66)].index.values\n",
    "to_remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8853a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words that need removal into a file for later use\n",
    "with open(\"../data/mf_words.json\", \"w\") as file:\n",
    "    json.dump(list(to_remove_list), file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efaa31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 6s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove the words from each of the messages\n",
    "X_train[\"message\"] = X_train[\"message\"].apply(lambda x: \" \".join([word for word in x.split() if word not in to_remove_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dfcaa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657423</th>\n",
       "      <td>hurt hip yesterday better wake knee feel fill ...</td>\n",
       "      <td>29</td>\n",
       "      <td>138</td>\n",
       "      <td>3.758621</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608008</th>\n",
       "      <td>hr bore</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>school monday</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007477</th>\n",
       "      <td>notic actual work anymor havent yesterday</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042354</th>\n",
       "      <td>direct messag iron chef</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message  word_count  \\\n",
       "657423   hurt hip yesterday better wake knee feel fill ...          29   \n",
       "608008                                             hr bore           7   \n",
       "12545                                        school monday           6   \n",
       "1007477          notic actual work anymor havent yesterday          16   \n",
       "1042354                            direct messag iron chef           7   \n",
       "\n",
       "         character_count  avg_word_len  stop_words_count  hashtags_count  \\\n",
       "657423               138      3.758621                14               0   \n",
       "608008                27      2.857143                 3               0   \n",
       "12545                 33      4.500000                 3               0   \n",
       "1007477              121      6.562500                 8               0   \n",
       "1042354               36      4.142857                 2               0   \n",
       "\n",
       "         numeric_count  upper_case_count  email_count  url_count  \\\n",
       "657423               0                 0            0          0   \n",
       "608008               1                 0            0          0   \n",
       "12545                0                 0            0          0   \n",
       "1007477              0                 0            0          1   \n",
       "1042354              0                 0            0          0   \n",
       "\n",
       "         mention_count  is_reply  \n",
       "657423               0         0  \n",
       "608008               0         0  \n",
       "12545                0         0  \n",
       "1007477              0         0  \n",
       "1042354              0         0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccada07",
   "metadata": {},
   "source": [
    "### Least frequent words\n",
    "\n",
    "We will now want to remove the words that are not very frequent as well, because they do not add value to the model. However, here I will want to also store how many least frequent words did each message have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d74cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what words occur only 1 time throughout the whole dataset\n",
    "word_counts = pd.Series(\" \".join(X_train[\"message\"]).split()).value_counts()\n",
    "to_remove_list = word_counts[word_counts < 2].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e23efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words that need removal into a file for later use\n",
    "with open(\"../data/lf_words.json\", \"w\") as file:\n",
    "    json.dump(list(to_remove_list), file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0924e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657423</th>\n",
       "      <td>hurt hip yesterday better wake knee feel fill ...</td>\n",
       "      <td>29</td>\n",
       "      <td>138</td>\n",
       "      <td>3.758621</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608008</th>\n",
       "      <td>hr bore</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>school monday</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007477</th>\n",
       "      <td>notic actual work anymor havent yesterday</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042354</th>\n",
       "      <td>direct messag iron chef</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message  word_count  \\\n",
       "657423   hurt hip yesterday better wake knee feel fill ...          29   \n",
       "608008                                             hr bore           7   \n",
       "12545                                        school monday           6   \n",
       "1007477          notic actual work anymor havent yesterday          16   \n",
       "1042354                            direct messag iron chef           7   \n",
       "\n",
       "         character_count  avg_word_len  stop_words_count  hashtags_count  \\\n",
       "657423               138      3.758621                14               0   \n",
       "608008                27      2.857143                 3               0   \n",
       "12545                 33      4.500000                 3               0   \n",
       "1007477              121      6.562500                 8               0   \n",
       "1042354               36      4.142857                 2               0   \n",
       "\n",
       "         numeric_count  upper_case_count  email_count  url_count  \\\n",
       "657423               0                 0            0          0   \n",
       "608008               1                 0            0          0   \n",
       "12545                0                 0            0          0   \n",
       "1007477              0                 0            0          1   \n",
       "1042354              0                 0            0          0   \n",
       "\n",
       "         mention_count  is_reply  \n",
       "657423               0         0  \n",
       "608008               0         0  \n",
       "12545                0         0  \n",
       "1007477              0         0  \n",
       "1042354              0         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32281fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.31 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>lf_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657423</th>\n",
       "      <td>hurt hip yesterday better wake knee feel fill ...</td>\n",
       "      <td>29</td>\n",
       "      <td>138</td>\n",
       "      <td>3.758621</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608008</th>\n",
       "      <td>hr bore</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>school monday</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007477</th>\n",
       "      <td>notic actual work anymor havent yesterday</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042354</th>\n",
       "      <td>direct messag iron chef</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message  word_count  \\\n",
       "657423   hurt hip yesterday better wake knee feel fill ...          29   \n",
       "608008                                             hr bore           7   \n",
       "12545                                        school monday           6   \n",
       "1007477          notic actual work anymor havent yesterday          16   \n",
       "1042354                            direct messag iron chef           7   \n",
       "\n",
       "         character_count  avg_word_len  stop_words_count  hashtags_count  \\\n",
       "657423               138      3.758621                14               0   \n",
       "608008                27      2.857143                 3               0   \n",
       "12545                 33      4.500000                 3               0   \n",
       "1007477              121      6.562500                 8               0   \n",
       "1042354               36      4.142857                 2               0   \n",
       "\n",
       "         numeric_count  upper_case_count  email_count  url_count  \\\n",
       "657423               0                 0            0          0   \n",
       "608008               1                 0            0          0   \n",
       "12545                0                 0            0          0   \n",
       "1007477              0                 0            0          1   \n",
       "1042354              0                 0            0          0   \n",
       "\n",
       "         mention_count  is_reply  lf_word_count  \n",
       "657423               0         0              0  \n",
       "608008               0         0              0  \n",
       "12545                0         0              0  \n",
       "1007477              0         0              0  \n",
       "1042354              0         0              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Add feature lf_word_count\n",
    "# This will improve time\n",
    "to_remove_set = set(to_remove_list)\n",
    "X_train[\"lf_word_count\"] = X_train[\"message\"].apply(lambda x: len([word for word in x.split() if word in to_remove_set]))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92482a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.44 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove the words from each of the messages\n",
    "X_train[\"message\"] = X_train[\"message\"].apply(lambda x: \" \".join([word for word in x.split() if word not in to_remove_set]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eecc62",
   "metadata": {},
   "source": [
    "### Separating manual features from messages\n",
    "\n",
    "Now that we are done preprocessing the text and only want to convert the sentences in our dataset to numbers, we can separate the features that we have drawn manually from the text and save them into a separate file to be used later.\n",
    "We will name this file m_feats_X_train.csv\n",
    "I will also save the transformer to use it later on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb191b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>lf_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657423</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608008</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007477</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042354</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.024627</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_count  character_count  avg_word_len  stop_words_count  \\\n",
       "657423     0.444444         0.358696      0.021492             0.350   \n",
       "608008     0.095238         0.057065      0.014135             0.075   \n",
       "12545      0.079365         0.073370      0.027542             0.075   \n",
       "1007477    0.238095         0.312500      0.044373             0.200   \n",
       "1042354    0.095238         0.081522      0.024627             0.050   \n",
       "\n",
       "         hashtags_count  numeric_count  upper_case_count  email_count  \\\n",
       "657423              0.0       0.000000               0.0          0.0   \n",
       "608008              0.0       0.111111               0.0          0.0   \n",
       "12545               0.0       0.000000               0.0          0.0   \n",
       "1007477             0.0       0.000000               0.0          0.0   \n",
       "1042354             0.0       0.000000               0.0          0.0   \n",
       "\n",
       "         url_count  mention_count  is_reply  lf_word_count  \n",
       "657423         0.0            0.0       0.0            0.0  \n",
       "608008         0.0            0.0       0.0            0.0  \n",
       "12545          0.0            0.0       0.0            0.0  \n",
       "1007477        0.2            0.0       0.0            0.0  \n",
       "1042354        0.0            0.0       0.0            0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get manual features and normalize them\n",
    "m_feats_X_train = X_train.drop(columns=\"message\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "m_feats_X_train = pd.DataFrame(scaler.fit_transform(m_feats_X_train), index=m_feats_X_train.index, columns=m_feats_X_train.columns)\n",
    "m_feats_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ec8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaled features and scaler\n",
    "m_feats_X_train.to_csv(\"../data/m_feats_X_train.csv\")\n",
    "with open(\"../data/m_feats_scaler.pkl\", \"wb\") as file:\n",
    "    dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38431fc",
   "metadata": {},
   "source": [
    "### Extract features using text feature extraction techniques\n",
    "\n",
    "1. TF - create a new dataframe using term frequency\n",
    "2. TF-IDF - create a new dataframe using term frequency and inverse document frequency\n",
    "3. Word2Vec - create a new dataframe using word2vec from spacy\n",
    "\n",
    "For all the above techniques, I will save the resulted dataset in the data folder so they can be later used for modeling.\n",
    "Having 3 types of feature extraction, I will use them to train some models. I will also use them in combination with manual features.\n",
    "Therefore, I will have 6 different datasets to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efae8509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657423     hurt hip yesterday better wake knee feel fill ...\n",
       "608008                                               hr bore\n",
       "12545                                          school monday\n",
       "1007477            notic actual work anymor havent yesterday\n",
       "1042354                              direct messag iron chef\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = X_train[\"message\"]\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d246ff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.3 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract TF using TfidfVectorizer\n",
    "tf_vectorizer = TfidfVectorizer(decode_error=\"ignore\", use_idf=False)\n",
    "tf_text_df = tf_vectorizer.fit_transform(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cddea3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is too big to be converted into a dataframe (memory allocation error)\n",
    "# Therefore, we will save this transformed dataset into a file and load it later to train our models\n",
    "save_npz(\"../data/sparse_tf_X_train.npz\", tf_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f58c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tf vectorizer, so we can use it on other text\n",
    "with open(\"../data/tf_vectorizer.pkl\", \"wb\") as file:\n",
    "    dump(tf_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17fa40ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.5 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract TF and TF-IDF using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(decode_error=\"ignore\")\n",
    "tfidf_text_df = tfidf_vectorizer.fit_transform(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d46ead43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is too big to be converted into a dataframe (memory allocation error)\n",
    "# Therefore, we will save this transformed dataset into a file and load it later to train our models\n",
    "save_npz(\"../data/sparse_tfidf_X_train.npz\", tfidf_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1db3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tfidf vectorizer, so we can use it on other text\n",
    "with open(\"../data/tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "    dump(tfidf_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7136f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word to vector embeddings\n",
    "# Disable everything spacy offers, besides word2vec\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8c1d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 56s\n",
      "Wall time: 13min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform every text entry into words embeddings\n",
    "all_embeddings = []\n",
    "for doc in nlp.pipe(text_df, batch_size=200):\n",
    "    all_embeddings.append(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02365a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.56 s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save the transformed dataset into a file to use for training\n",
    "np.save(\"../data/word2vec_X_train.npy\", all_embeddings, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
